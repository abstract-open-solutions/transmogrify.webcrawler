
transmogrify.webcrawler
=======================

A transmogrifier blueprint source which will crawl a url reading in all pages
until all have been crawled.

Options
-------

site_url
  URL to start crawling. The URL will be treated as the base and any links outside
  this base will be ignored

ignore
   Regular expressions for urls not to follow
  
alias_bases
   Substitutions for url bases. This is useful where url to access is not the same as absolute
   urls of links in the pages

patterns
   Regular expressions to substitute before html is parsed. New line seperated 
   
subs
   Text to replace 


checkext
   checkext
   
verbose
   verbose
   
maxpage
   maxpage
   
nonames
   nonames
   
cache
   cache



>>> from os.path import dirname, abspath
>>> config = """
... [transmogrifier]
... pipeline =
...     webcrawler
...     clean
...     printer
...     
... [webcrawler]
... blueprint = transmogrify.webcrawler
... site_url  = file://%s/test_staticsite
... alias_bases = http://somerandomsite file:///
... patterns =
...		(?s)<SCRIPT.*Abbreviation"\) 
...		(?s)MakeLink\('(?P<u>[^']*)','(?P<a>[^']*)'\)
...     (?s)State=.*<body[^>]*>
... subs = 
...     </head><body>
...		<a href="\g<u>">\g<a></a>
...     <br>
...
... [clean]
... blueprint = collective.transmogrifier.sections.manipulator
... delete = 
...     _content
...
... [printer]
... blueprint = collective.transmogrifier.sections.tests.pprinter
...
... """ % abspath(dirname(__file__)).replace('\\','/')

>>> from collective.transmogrifier.tests import registerConfig
>>> registerConfig(u'transmogrify.webcrawler.webcrawler.test', config)

>>> from collective.transmogrifier.transmogrifier import Transmogrifier
>>> transmogrifier = Transmogrifier(plone)
>>> transmogrifier(u'transmogrify.webcrawler.webcrawler.test')
{'_backlinks': [],
 '_content_info': {'content-type': 'text/html'},
 '_origin': 'file://.../test_staticsite',
 '_path': '',
 '_site_url': 'file://.../test_staticsite/',
 '_sortorder': 0}
 ...

The item attributes have the following meanings

_content
  The main content of the url
_content_info
  Headers returned
_path
  the path of the url not including the base
_origin
  the original path in case retriving the url caused a redirection
_site_url
  the base of the url
_sortoder
  a count on when this path was first encountered in when parsing links in html
_backlinks
  A list of tuples of which pages linked to this item. (url, path)

>>> transmogrifier(u'transmogrify.webcrawler.webcrawler.test')
{...
 '_path': '',
 ...}
{...
 '_path': 'file2.htm',
 ...}
{...
 '_path': 'subfolder',
 ...}
{...
 '_path': 'egenius-plone.gif',
 ...}
{...
 '_path': 'plone_schema.png',
 ...}
...
